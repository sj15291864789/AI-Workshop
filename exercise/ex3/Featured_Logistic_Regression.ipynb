{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Notebook is used to demostrate the featured logistic regression\n",
    "It will include following steps:\n",
    "* load data\n",
    "* extract features from data\n",
    "* use extracted features instead of pixes to train the logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from six.moves import cPickle as pickle\n",
    "from scipy.ndimage import uniform_filter\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('../data/notMNIST.pickle', 'rb') as f:\n",
    "    data_set = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset size:\n",
      "(16000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "train_size = 16000\n",
    "valid_size = 1000\n",
    "test_size = 1000\n",
    "train_dataset = data_set['train_dataset'][:train_size,:,:]\n",
    "train_label = data_set['train_labels'][:train_size]\n",
    "valid_dataset = data_set['valid_dataset'][:valid_size,:,:]\n",
    "valid_label = data_set['valid_labels'][:valid_size]\n",
    "test_dataset = data_set['test_dataset'][:test_size,:,:]\n",
    "test_label = data_set['test_labels'][:test_size]\n",
    "# turn our y label from index in 1 to 10 into array of R1x10 for example turn 2 into [0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "print(\"train_dataset size:\")\n",
    "print(np.shape(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs):\n",
    "  num_images = imgs.shape[0]\n",
    "  if num_images == 0:\n",
    "    return np.array([])\n",
    "  feats = hog_feature(imgs[0].squeeze())\n",
    "  imgs_features = np.zeros((num_images, feats.shape[0]))\n",
    "  for i in xrange(0, num_images):\n",
    "    imgs_features[i,:] = hog_feature(imgs[i].squeeze())\n",
    "  return imgs_features\n",
    "def hog_feature(image):\n",
    "  \"\"\"Compute Histogram of Gradient (HOG) feature for an image\n",
    "  \n",
    "       Modified from skimage.feature.hog\n",
    "       http://pydoc.net/Python/scikits-image/0.4.2/skimage.feature.hog\n",
    "     \n",
    "     Reference:\n",
    "       Histograms of Oriented Gradients for Human Detection\n",
    "       Navneet Dalal and Bill Triggs, CVPR 2005\n",
    "     \n",
    "    Parameters:\n",
    "      im : an input grayscale or rgb image\n",
    "      \n",
    "    Returns:\n",
    "      feat: Histogram of Gradient (HOG) feature\n",
    "    \n",
    "  \"\"\"\n",
    "  \n",
    "  # convert rgb to grayscale if needed\n",
    "  sx, sy = image.shape # image size\n",
    "  orientations = 9 # number of gradient bins\n",
    "  cx, cy = (4, 4) # pixels per cell\n",
    "  gx = np.zeros(image.shape)\n",
    "  gy = np.zeros(image.shape)\n",
    "  gx[:, :-1] = np.diff(image, n=1, axis=1) # compute gradient on x-direction\n",
    "  gy[:-1, :] = np.diff(image, n=1, axis=0) # compute gradient on y-direction\n",
    "  grad_mag = np.sqrt(gx ** 2 + gy ** 2) # gradient magnitude\n",
    "  grad_ori = np.arctan2(gy, (gx + 1e-15)) * (180 / np.pi) + 90 # gradient orientation\n",
    "\n",
    "  n_cellsx = int(np.floor(sx / cx))  # number of cells in x\n",
    "  n_cellsy = int(np.floor(sy / cy))  # number of cells in y\n",
    "  # compute orientations integral images\n",
    "  orientation_histogram = np.zeros((n_cellsx, n_cellsy, orientations))\n",
    "  for i in range(orientations):\n",
    "    # create new integral image for this orientation\n",
    "    # isolate orientations in this range\n",
    "    temp_ori = np.where(grad_ori < 180 / orientations * (i + 1),\n",
    "                        grad_ori, 0)\n",
    "    temp_ori = np.where(grad_ori >= 180 / orientations * i,\n",
    "                        temp_ori, 0)\n",
    "    # select magnitudes for those orientations\n",
    "    cond2 = temp_ori > 0\n",
    "    temp_mag = np.where(cond2, grad_mag, 0)\n",
    "    orientation_histogram[:,:,i] = uniform_filter(temp_mag, size=(cx, cy))[cx/2::cx, cy/2::cy].T\n",
    "  \n",
    "  return orientation_histogram.ravel()\n",
    "def accuracy(predictions, labels):\n",
    "  print predictions.shape\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == labels)\n",
    "          / predictions.shape[0])\n",
    "num_classes = 10\n",
    "y_train_label = (np.arange(num_classes) == train_label[:,None]).astype(np.int32)\n",
    "featured_train_dataset = extract_features(train_dataset)\n",
    "featured_valid_dataset = extract_features(valid_dataset)\n",
    "featured_test_dataset = extract_features(test_dataset)\n",
    "num_features = featured_train_dataset.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  tf_train_dataset = tf.constant(featured_train_dataset, dtype=tf.float32)\n",
    "  tf_train_labels = tf.constant(y_train_label)\n",
    "  tf_valid_dataset = tf.constant(featured_valid_dataset, dtype=tf.float32)\n",
    "  tf_test_dataset = tf.constant(featured_test_dataset, dtype=tf.float32)\n",
    "  \n",
    "    \n",
    "  weights = tf.Variable(\n",
    "    tf.truncated_normal([num_features, num_classes]), dtype=tf.float32)\n",
    "  biases = tf.Variable(tf.zeros([num_classes]))\n",
    "  \n",
    "  logits = tf.matmul(tf_train_dataset, weights) + biases\n",
    "    \n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  \n",
    "  optimizer = tf.train.GradientDescentOptimizer(10).minimize(loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_prediction = tf.nn.softmax(\n",
    "    tf.matmul(tf_valid_dataset, weights) + biases)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(tf_test_dataset, weights) + biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "()\n",
      "Loss at step 0: 2.489006\n",
      "16000\n",
      "(16000, 10)\n",
      "Training accuracy: 9.1%\n",
      "(1000, 10)\n",
      "Validation accuracy: 11.5%\n",
      "\n",
      "Loss at step 200: 0.802565\n",
      "16000\n",
      "(16000, 10)\n",
      "Training accuracy: 78.9%\n",
      "(1000, 10)\n",
      "Validation accuracy: 80.2%\n",
      "\n",
      "Loss at step 400: 0.693159\n",
      "16000\n",
      "(16000, 10)\n",
      "Training accuracy: 81.5%\n",
      "(1000, 10)\n",
      "Validation accuracy: 82.2%\n",
      "\n",
      "Loss at step 600: 0.645074\n",
      "16000\n",
      "(16000, 10)\n",
      "Training accuracy: 82.4%\n",
      "(1000, 10)\n",
      "Validation accuracy: 83.7%\n",
      "\n",
      "Loss at step 800: 0.615777\n",
      "16000\n",
      "(16000, 10)\n",
      "Training accuracy: 83.2%\n",
      "(1000, 10)\n",
      "Validation accuracy: 84.2%\n",
      "\n",
      "(1000, 10)\n",
      "Test accuracy: 89.0%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 801\n",
    "\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  # This is a one-time operation which ensures the parameters get initialized as\n",
    "  # we described in the graph: random weights for the matrix, zeros for the\n",
    "  # biases. \n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  print()\n",
    "  for step in range(num_steps):\n",
    "    # Run the computations. We tell .run() that we want to run the optimizer,\n",
    "    # and get the loss value and the training predictions returned as numpy\n",
    "    # arrays.\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction])\n",
    "    \n",
    "    if (step % 200 == 0):\n",
    "      print('Loss at step %d: %f' % (step, l))\n",
    "      print predictions.shape[0]\n",
    "      print('Training accuracy: %.1f%%' % accuracy(\n",
    "        predictions, train_label))\n",
    "      # Calling .eval() on valid_prediction is basically like calling run(), but\n",
    "      # just to get that one numpy array. Note that it recomputes all its graph\n",
    "      # dependencies.\n",
    "      print('Validation accuracy: %.1f%%\\n' % accuracy(\n",
    "        valid_prediction.eval(), valid_label))\n",
    "\n",
    "# print the accuracy of our model.\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:11: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (28,28) (7,7) (28,28) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-4feefc918665>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtemp\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (28,28) (7,7) (28,28) "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKkAAACuCAYAAABN0C2XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAACxxJREFUeJzt3WuMVdUZxvH/AxJHB6oJM6NtoIp4r4IDWK9A6z0kBU0T\nZLQx1mCCpQklTWqJbUiamJoYwVakNSGtgpcGPyiYWrEItUE0RIhYq7QJggi1U8CCBrBcZvXDPoPD\nDDDsfdaeswaeX3I+nJ1z1n4PPLP2de2lEAJmKetT6wLMuuOQWvIcUkueQ2rJc0gteQ6pJc8hteQ5\npJa8k8psXNJA4GZgI/BFmeuyXqcOOBtYEkLYfrQPlhpSsoA+U/I6rHe7E3j2aB8oe3O/seT2rffb\n2N0Hyg6pN/HWnW4z4gMnS16hkEqaKmmDpD2S3pJ0eezCzNrlDqmk24FHgJlAM7AWWCKpIXJtZkCx\nnnQ68EQIYX4IYR0wBdgN3BO1MrOKXCGV1A8YCbzWvixkd00vBa6KW5pZJm9P2gD0BVo7LW8FzoxS\nkVknsY7uBXgcipUib0i3AQeAMzotb6Jr72oWRa6QhhD2AauB69uXSVLl/cq4pZllily7nwU8JWk1\nsIrsaP9U4MmIdZkdlDukIYSFlXOivyDb7L8D3BxC2Bq7ODMAlTnuXtIIst0DsyMZGUJYc7QP+Nq9\nJc8hteQ5pJa8su/MB2DYsGH079+/6nZWrvRZrhORe1JLnkNqyXNILXkOqSWvyJ35oyUtlrRFUpuk\n8WUUZtauSE9aT3YpdCq+Pc96QJFr968Ar8DBO6DMSuV9UkueQ2rJc0gteT1yWXTDhg2cdNKhq2po\naKCxsbEnVm+9XI+EdMiQIVGu3duJKXdIJdUD55KNEAU4R9Jw4NMQwscxizODYj3pKGA52TnSQPbI\nHYCn8FNMrARFzpO+jg+4rAc5bJY8h9SS55Ba8hxSS16PnCft27dvl5P5x5sXX3wxanu33npr1PZ6\nM/ekljyH1JLnkFry8j6OfIakVZI+k9Qq6QVJ55dVnBnk70lHA48BVwA3AP2AVyWdErsws3a5DrlD\nCOM6vpd0N/AfsskeVsQry+xL1e6Tnk52k8mnEWoxO6zCIa0MwnsUWBFCeD9eSWaHquYM+1zgYuCa\nSLWYHVahkEqaA4wDRocQPunu8+vXr+9yxampqYmmpqYiq7cTTJE78+cAE4CxIYRNx/KdoUOHMmDA\ngLyrMgNyhlTSXKAFGA/sktQ+n9POEILntrdS5D1wmgJ8BfgL8K8Or4lxyzL7Ut7zpL6Maj3OobPk\nOaSWPIfUkueQWvJ6ZEzHvHnzGDFiRNXtpPw41GHDhkVtL+ZvLXNqzp7gntSS55Ba8hxSS17e4SNT\nJK2VtLPyWinplrKKM4P8PenHwP1kd+KPBJYBiyRdFLsws3Z5L4v+sdOin0m6D7gS+CBaVWYdFD4F\nJakP2Y0lpwJvRqvIrJMi95NeQhbKOuBz4LYQwrrYhZm1K3J0vw4YTjas+TfAfEkXRq3KrIMiT3re\nD3xYebtG0jeBacB9R/rO9OnTOe200w5Z1tLSQktLS97V2wkoxmXRPsDJR/vA7Nmzo1wWtRNT3uEj\nDwJ/IjsVNQC4ExgL3BS/NLNM3p70DGA+8FVgJ/AucFMIYVnswsza5T1POrmsQsyOxNfuLXkOqSXP\nIbXkOaSWvB4ZPrJgwQKWL1/eE6uqmYULF9a6hOOWe1JLnkNqyXNILXkOqSWvqpBWpsxpkzQrVkFm\nnVXzzPzLgXuBtfHKMeuqUEgl9QeeBiYDO6JWZNZJ0Z70ceAl3/1kPaHIGKdJwGXAqPjlmHWV96bn\nQWRzN90YQth3rN9bvHgxdXV1hyxrbm6mubk5z+rtBJW3Jx0JNAKr9eVj3/oCYyT9EDg5HOYRbuPH\nj2fQoEHVVWonrLwhXQpc2mnZk2QPhnjocAE1q1beO/N3AYdM0ShpF7A9hOAnmFgpYlxxcu9ppar6\nVr0QwnUxCjE7El+7t+Q5pJY8h9SSpzLPGkkaAayO1V5jY2OspgDYunVrtLYmTow7vWrM/5fnn38+\nWlsAgwcPrrqNvXv30traCjAyhLDmaJ91T2rJc0gteQ6pJc8hteTlnSJnZmW4SMfX+91/06y4Ilec\n3gOuB9rvgtofrxyzroqEdH8IId65G7NuFNknPU/SFknrJT0tqfqTZmZHkTekbwF3AzcDU4AhwF8l\n1Ueuy+ygvPeTLunw9j1Jq4CPyCYd+33MwszaVXWrXghhp6R/AudGqseOQ7t27WL37t2HLGtrazvm\n71cV0sr4+6Fkkz2YHVZ9fT319YfuEXa4dt+tvOdJH5Y0RtJZkq4GXiA7BfVcnnbM8sjbkw4CngUG\nAluBFcCVIYTtsQsza5f3wMnzLFqP87V7S55DaslzSC15Dqklr1eNcbJiJkyYELW9RYsWxWzOY5ys\n93NILXkOqSUvd0glfU3SAknbJO2WtLay72lWirxPej4deAN4jeye0m3AecB/45dmlsl77f6nwKYQ\nwuQOyz6KWI9ZF3k3998B3pa0UFKrpDWSJnf7LbMq5A3pOcB9wD+Am4DfAr+W9L3YhZm1y7u57wOs\nCiH8vPJ+raRvkAX36aiVmVXk7Uk/IZvEoaMPgK/HKcesq7whfQO4oNOyC/DBk5Uob0hnA1dWZmce\nKukOsvlF58QvzSyTK6QhhLeB24AW4G/AA8C0EMIfSqjNetDmzZtrXcIR5R4tGkJ4GXi5hFqshrZs\n2ZLsrIW+dm/Jc0gteQ6pJa/qGfG6Udf9R6xsO3bs6PYz+/btO6bPlaDbjJQ9fOQO4JnSVmDHgztD\nCM8e7QNlh3Qg2S19G4EvSluR9UZ1wNnAku6egFNqSM1i8IGTJc8hteQ5pJY8h9SSl0RIJU2VtEHS\nHklvSbq8QBujJS2uzIzSJml8FfXMkLRK0meVYTIvSDq/ivamVEbV7qy8Vkq6pWh7nepskzSr4Pej\nTh5X1kjimodU0u3AI8BMoBlYCyyR1JCzqXrgHWAqUO0pi9HAY8AVwA1AP+BVSacUbO9j4H5gZOW1\nDFgk6aKiBVb+kO8l+/eqxnvAGcCZlde1BetpH0n8P7LTjhcBPybGSOIQQk1fZNPu/KrDewGbgZ9U\n0WYbMD5ijQ2VNq+N2OZ24PsFv9ufbJzZdcByYFbBdmYCayL9noeA18vISE17Ukn9yHqW19qXhewX\nLwWuqlVdh3E6We/8abUNSeojaRJwKvBmwWYeB14KISyrth7iTR5X2kjiWm/uG4C+QOdpKFrJNj01\nJ0nAo8CKEEI1+2uXSPqcbHM4F7gthLCuQDuTgMuAGUVr6SDm5HGljSQu+waTokT1+5WxzAUuBq6p\nsp11wHCyXvm7wHxJY/IEVdIgsj+YG0MI+6qshxB38rjSRhLXuifdBhwg23HvqImuvWuPkzQHGAd8\nK4TwSTVthRD2hxA+DCGsCSE8QHbAMy1nMyOBRmC1pH2S9gFjgWmS9lZ6/Wpq3AkUnTyutJHENQ1p\npTdYTTY1OXBw83o9sLJWdVXqmANMAL4dQthUwir6ACfn/M5S4FKyzf3wyuttsp5qeGV/vrAOk8cV\n+YMsbyRxGUdjOY8KJwJ7gLuAC4EnyI58G3O2U0/2n3YZ2ZH4jyrvBxeoaS7ZqZPRZL18+6uu4G98\nkOzUzlnAJcAvySZpuy7Cv181R/cPA2MqdV0N/JlsCzawQFujyPa3Z5AF/Q7gc2BS1b+x1iGt/MAf\nkN3Ot4fsiHdUgTbGVsJ5oNPrdwXaOlw7B4C7Cv6+ecCHld/3b+DVGAGttL2sipA+R3a6bw+wiWwi\nuSFV1DIOeBfYDfwduCfGb/Stepa8Wh84mXXLIbXkOaSWPIfUkueQWvIcUkueQ2rJc0gteQ6pJc8h\nteQ5pJY8h9SS938W41YdNuMpqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffac585d090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for(i in np.arrange(10)):\n",
    "#     plt.subplot(i, 0)\n",
    "#     plt.imshow(featured_train_dataset[i].astype('uint8'))\n",
    "#     plt.axis('off')\n",
    "#         if i == 0:\n",
    "#             plt.title(cls_name)\n",
    "# plt.show()\n",
    "num_feature_size = featured_train_dataset.shape[1]\n",
    "orientations = 9\n",
    "size = np.sqrt(num_feature_size / 9)\n",
    "image = featured_train_dataset[0,:].reshape(size,size,orientations)\n",
    "temp = np.zeros((28,28))\n",
    "for i in np.arange(orientations):\n",
    "    plt.subplot(4, 4, i + 1)\n",
    "    plt.imshow(image[:,:,i])\n",
    "    temp += image[:,:,i]\n",
    "plt.subplot(4, 4, 10)\n",
    "plt.imshow(np.array(train_dataset[0] > 0))\n",
    "plt.show()\n",
    "plt.subplot(4, 4, 10)\n",
    "plt.imshow(np.array(temp > 0, dtype=np.int32))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
